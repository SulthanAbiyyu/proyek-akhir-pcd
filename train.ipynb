{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DATASET_PATH = Path('./cifake/')\n",
    "TRAIN_DATASET_PATH = ROOT_DATASET_PATH / 'train'\n",
    "TEST_DATASET_PATH = ROOT_DATASET_PATH / 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6748ff9dbf645f480d9ce8e554f8660",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c429d2c843f340b3aae0df8b55dd47c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15206fa0e2c64511b38f4f3b9e840287",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f8e42df1b25488c8330631f581a65bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed617435415347df93ccf4e10fc3e2ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a67a3280509e409f9246c57760ff4db9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec6ac9d576324703b503851cf12280c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2135f1c32d8f4496aea963f8fd623083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e299c0d94e5a41e685baff1c27635ae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1c576638f1d4338863f236684fb0133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = load_dataset('imagefolder', data_dir=\"./cifake/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data[\"train\"].features[\"label\"].names\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = i\n",
    "    id2label[i] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8d65cad47fe446ab3e4bfb998786b9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)rocessor_config.json:   0%|          | 0.00/266 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\user\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0800387c91e84b9e85a4bbed3333a579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/69.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b562a660ccd8403aba6ce287065d2912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/103M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/resnet-50 were not used when initializing ResNetModel: ['classifier.1.bias', 'classifier.1.weight']\n",
      "- This IS expected if you are initializing ResNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ResNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ConvNextImageProcessor {\n",
       "  \"crop_pct\": 0.875,\n",
       "  \"do_normalize\": true,\n",
       "  \"do_rescale\": true,\n",
       "  \"do_resize\": true,\n",
       "  \"image_mean\": [\n",
       "    0.485,\n",
       "    0.456,\n",
       "    0.406\n",
       "  ],\n",
       "  \"image_processor_type\": \"ConvNextImageProcessor\",\n",
       "  \"image_std\": [\n",
       "    0.229,\n",
       "    0.224,\n",
       "    0.225\n",
       "  ],\n",
       "  \"resample\": 3,\n",
       "  \"rescale_factor\": 0.00392156862745098,\n",
       "  \"size\": {\n",
       "    \"shortest_edge\": 224\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = \"microsoft/resnet-50\"\n",
    "image_processor = AutoImageProcessor.from_pretrained(checkpoint)\n",
    "\n",
    "image_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import (\n",
    "    CenterCrop,\n",
    "    Compose,\n",
    "    Normalize,\n",
    "    RandomHorizontalFlip,\n",
    "    RandomResizedCrop,\n",
    "    Resize,\n",
    "    ToTensor,\n",
    ")\n",
    "\n",
    "normalize = Normalize(mean=image_processor.image_mean,\n",
    "                      std=image_processor.image_std)\n",
    "if \"height\" in image_processor.size:\n",
    "    size = (image_processor.size[\"height\"], image_processor.size[\"width\"])\n",
    "    crop_size = size\n",
    "    max_size = None\n",
    "elif \"shortest_edge\" in image_processor.size:\n",
    "    size = image_processor.size[\"shortest_edge\"]\n",
    "    crop_size = (size, size)\n",
    "    max_size = image_processor.size.get(\"longest_edge\")\n",
    "\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        RandomResizedCrop(crop_size),\n",
    "        RandomHorizontalFlip(),\n",
    "        ToTensor(),\n",
    "        normalize,\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        Resize(size),\n",
    "        CenterCrop(crop_size),\n",
    "        ToTensor(),\n",
    "        normalize,\n",
    "    ]\n",
    ")\n",
    "\n",
    "def preprocess_train(example_batch):\n",
    "    example_batch[\"pixel_values\"] = [\n",
    "        train_transforms(image.convert(\"RGB\")) for image in example_batch[\"image\"]\n",
    "    ]\n",
    "    return example_batch\n",
    "\n",
    "def preprocess_val(example_batch):\n",
    "    example_batch[\"pixel_values\"] = [val_transforms(\n",
    "        image.convert(\"RGB\")) for image in example_batch[\"image\"]]\n",
    "    return example_batch\n",
    "\n",
    "splits = data[\"train\"].train_test_split(test_size=0.1)\n",
    "train_ds = splits['train']\n",
    "val_ds = splits['test']\n",
    "\n",
    "train_ds.set_transform(preprocess_train)\n",
    "val_ds.set_transform(preprocess_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ResNetForImageClassification were not initialized from the model checkpoint at microsoft/resnet-50 and are newly initialized because the shapes did not match:\n",
      "- classifier.1.weight: found shape torch.Size([1000, 2048]) in the checkpoint and torch.Size([2, 2048]) in the model instantiated\n",
      "- classifier.1.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    checkpoint,\n",
    "    label2id=label2id,\n",
    "    id2label=id2label,\n",
    "    ignore_mismatched_sizes=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=eval_pred.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "model_name = checkpoint.split(\"/\")[-1]\n",
    "\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-cifake\",\n",
    "    remove_unused_columns=False,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    gradient_accumulation_steps=4,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=3,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def collate_fn(examples):\n",
    "    pixel_values = torch.stack([example[\"pixel_values\"]\n",
    "                               for example in examples])\n",
    "    labels = torch.tensor([example[\"label\"] for example in examples])\n",
    "    return {\"pixel_values\": pixel_values, \"labels\": labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=image_processor,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msulthanabiyyu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Code\\Project\\Java\\Kuliah\\Semester 5\\PCD\\proyek-akhir\\wandb\\run-20230922_235254-ah5vtwuw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sulthanabiyyu/huggingface/runs/ah5vtwuw' target=\"_blank\">zany-wildflower-3</a></strong> to <a href='https://wandb.ai/sulthanabiyyu/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sulthanabiyyu/huggingface' target=\"_blank\">https://wandb.ai/sulthanabiyyu/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sulthanabiyyu/huggingface/runs/ah5vtwuw' target=\"_blank\">https://wandb.ai/sulthanabiyyu/huggingface/runs/ah5vtwuw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f047ed23dc71428abd96e16630f068f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6928, 'learning_rate': 2.3696682464454976e-06, 'epoch': 0.01}\n",
      "{'loss': 0.6921, 'learning_rate': 4.739336492890995e-06, 'epoch': 0.03}\n",
      "{'loss': 0.6911, 'learning_rate': 7.109004739336493e-06, 'epoch': 0.04}\n",
      "{'loss': 0.6908, 'learning_rate': 9.47867298578199e-06, 'epoch': 0.06}\n",
      "{'loss': 0.6894, 'learning_rate': 1.184834123222749e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6881, 'learning_rate': 1.4218009478672985e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6885, 'learning_rate': 1.6587677725118483e-05, 'epoch': 0.1}\n",
      "{'loss': 0.686, 'learning_rate': 1.895734597156398e-05, 'epoch': 0.11}\n",
      "{'loss': 0.6847, 'learning_rate': 2.132701421800948e-05, 'epoch': 0.13}\n",
      "{'loss': 0.6812, 'learning_rate': 2.369668246445498e-05, 'epoch': 0.14}\n",
      "{'loss': 0.6781, 'learning_rate': 2.6066350710900477e-05, 'epoch': 0.16}\n",
      "{'loss': 0.6762, 'learning_rate': 2.843601895734597e-05, 'epoch': 0.17}\n",
      "{'loss': 0.6743, 'learning_rate': 3.080568720379147e-05, 'epoch': 0.18}\n",
      "{'loss': 0.668, 'learning_rate': 3.3175355450236966e-05, 'epoch': 0.2}\n",
      "{'loss': 0.6614, 'learning_rate': 3.554502369668247e-05, 'epoch': 0.21}\n",
      "{'loss': 0.658, 'learning_rate': 3.791469194312796e-05, 'epoch': 0.23}\n",
      "{'loss': 0.6486, 'learning_rate': 4.028436018957346e-05, 'epoch': 0.24}\n",
      "{'loss': 0.6431, 'learning_rate': 4.265402843601896e-05, 'epoch': 0.26}\n",
      "{'loss': 0.6329, 'learning_rate': 4.502369668246446e-05, 'epoch': 0.27}\n",
      "{'loss': 0.6255, 'learning_rate': 4.739336492890996e-05, 'epoch': 0.28}\n",
      "{'loss': 0.6134, 'learning_rate': 4.976303317535545e-05, 'epoch': 0.3}\n",
      "{'loss': 0.5969, 'learning_rate': 4.976290832455216e-05, 'epoch': 0.31}\n",
      "{'loss': 0.5875, 'learning_rate': 4.949947312961012e-05, 'epoch': 0.33}\n",
      "{'loss': 0.5801, 'learning_rate': 4.923603793466807e-05, 'epoch': 0.34}\n",
      "{'loss': 0.5582, 'learning_rate': 4.8972602739726034e-05, 'epoch': 0.36}\n",
      "{'loss': 0.549, 'learning_rate': 4.8709167544783986e-05, 'epoch': 0.37}\n",
      "{'loss': 0.5392, 'learning_rate': 4.8445732349841945e-05, 'epoch': 0.38}\n",
      "{'loss': 0.5218, 'learning_rate': 4.8182297154899896e-05, 'epoch': 0.4}\n",
      "{'loss': 0.5015, 'learning_rate': 4.791886195995785e-05, 'epoch': 0.41}\n",
      "{'loss': 0.4949, 'learning_rate': 4.7655426765015806e-05, 'epoch': 0.43}\n",
      "{'loss': 0.5005, 'learning_rate': 4.7391991570073765e-05, 'epoch': 0.44}\n",
      "{'loss': 0.4816, 'learning_rate': 4.712855637513172e-05, 'epoch': 0.46}\n",
      "{'loss': 0.4879, 'learning_rate': 4.6865121180189675e-05, 'epoch': 0.47}\n",
      "{'loss': 0.4954, 'learning_rate': 4.6601685985247633e-05, 'epoch': 0.48}\n",
      "{'loss': 0.4646, 'learning_rate': 4.6338250790305585e-05, 'epoch': 0.5}\n",
      "{'loss': 0.4541, 'learning_rate': 4.6074815595363544e-05, 'epoch': 0.51}\n",
      "{'loss': 0.4682, 'learning_rate': 4.58113804004215e-05, 'epoch': 0.53}\n",
      "{'loss': 0.4473, 'learning_rate': 4.5547945205479454e-05, 'epoch': 0.54}\n",
      "{'loss': 0.4151, 'learning_rate': 4.528451001053741e-05, 'epoch': 0.55}\n",
      "{'loss': 0.4595, 'learning_rate': 4.5021074815595364e-05, 'epoch': 0.57}\n",
      "{'loss': 0.4377, 'learning_rate': 4.4757639620653316e-05, 'epoch': 0.58}\n",
      "{'loss': 0.4246, 'learning_rate': 4.449420442571128e-05, 'epoch': 0.6}\n",
      "{'loss': 0.4292, 'learning_rate': 4.423076923076923e-05, 'epoch': 0.61}\n",
      "{'loss': 0.4336, 'learning_rate': 4.396733403582719e-05, 'epoch': 0.63}\n",
      "{'loss': 0.4357, 'learning_rate': 4.370389884088514e-05, 'epoch': 0.64}\n",
      "{'loss': 0.4301, 'learning_rate': 4.34404636459431e-05, 'epoch': 0.65}\n",
      "{'loss': 0.3905, 'learning_rate': 4.317702845100105e-05, 'epoch': 0.67}\n",
      "{'loss': 0.4137, 'learning_rate': 4.291359325605901e-05, 'epoch': 0.68}\n",
      "{'loss': 0.4119, 'learning_rate': 4.265015806111697e-05, 'epoch': 0.7}\n",
      "{'loss': 0.3921, 'learning_rate': 4.238672286617492e-05, 'epoch': 0.71}\n",
      "{'loss': 0.4231, 'learning_rate': 4.212328767123288e-05, 'epoch': 0.73}\n",
      "{'loss': 0.4031, 'learning_rate': 4.185985247629083e-05, 'epoch': 0.74}\n",
      "{'loss': 0.4114, 'learning_rate': 4.159641728134879e-05, 'epoch': 0.75}\n",
      "{'loss': 0.4137, 'learning_rate': 4.133298208640675e-05, 'epoch': 0.77}\n",
      "{'loss': 0.3867, 'learning_rate': 4.10695468914647e-05, 'epoch': 0.78}\n",
      "{'loss': 0.3995, 'learning_rate': 4.080611169652266e-05, 'epoch': 0.8}\n",
      "{'loss': 0.368, 'learning_rate': 4.054267650158061e-05, 'epoch': 0.81}\n",
      "{'loss': 0.3674, 'learning_rate': 4.027924130663857e-05, 'epoch': 0.82}\n",
      "{'loss': 0.3706, 'learning_rate': 4.001580611169653e-05, 'epoch': 0.84}\n",
      "{'loss': 0.3816, 'learning_rate': 3.975237091675448e-05, 'epoch': 0.85}\n",
      "{'loss': 0.3508, 'learning_rate': 3.948893572181244e-05, 'epoch': 0.87}\n",
      "{'loss': 0.385, 'learning_rate': 3.922550052687039e-05, 'epoch': 0.88}\n",
      "{'loss': 0.371, 'learning_rate': 3.896206533192835e-05, 'epoch': 0.9}\n",
      "{'loss': 0.3498, 'learning_rate': 3.86986301369863e-05, 'epoch': 0.91}\n",
      "{'loss': 0.3635, 'learning_rate': 3.843519494204426e-05, 'epoch': 0.92}\n",
      "{'loss': 0.3715, 'learning_rate': 3.8171759747102217e-05, 'epoch': 0.94}\n",
      "{'loss': 0.3682, 'learning_rate': 3.790832455216017e-05, 'epoch': 0.95}\n",
      "{'loss': 0.3506, 'learning_rate': 3.764488935721813e-05, 'epoch': 0.97}\n",
      "{'loss': 0.3647, 'learning_rate': 3.738145416227608e-05, 'epoch': 0.98}\n",
      "{'loss': 0.365, 'learning_rate': 3.711801896733404e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5fd1fe11ddb4cdea352dfdf6cb009b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3254718780517578, 'eval_f1': 0.8436485730274202, 'eval_runtime': 205.6149, 'eval_samples_per_second': 48.635, 'eval_steps_per_second': 1.522, 'epoch': 1.0}\n",
      "{'loss': 0.3291, 'learning_rate': 3.6854583772391995e-05, 'epoch': 1.01}\n",
      "{'loss': 0.3617, 'learning_rate': 3.6591148577449954e-05, 'epoch': 1.02}\n",
      "{'loss': 0.3472, 'learning_rate': 3.6327713382507905e-05, 'epoch': 1.04}\n",
      "{'loss': 0.3676, 'learning_rate': 3.606427818756586e-05, 'epoch': 1.05}\n",
      "{'loss': 0.3533, 'learning_rate': 3.5800842992623816e-05, 'epoch': 1.07}\n",
      "{'loss': 0.3574, 'learning_rate': 3.5537407797681774e-05, 'epoch': 1.08}\n",
      "{'loss': 0.3606, 'learning_rate': 3.527397260273973e-05, 'epoch': 1.09}\n",
      "{'loss': 0.348, 'learning_rate': 3.5010537407797684e-05, 'epoch': 1.11}\n",
      "{'loss': 0.3644, 'learning_rate': 3.4747102212855636e-05, 'epoch': 1.12}\n",
      "{'loss': 0.3502, 'learning_rate': 3.4483667017913594e-05, 'epoch': 1.14}\n",
      "{'loss': 0.3625, 'learning_rate': 3.4220231822971546e-05, 'epoch': 1.15}\n",
      "{'loss': 0.3317, 'learning_rate': 3.3956796628029505e-05, 'epoch': 1.17}\n",
      "{'loss': 0.3593, 'learning_rate': 3.369336143308746e-05, 'epoch': 1.18}\n",
      "{'loss': 0.3364, 'learning_rate': 3.342992623814542e-05, 'epoch': 1.19}\n",
      "{'loss': 0.3364, 'learning_rate': 3.316649104320337e-05, 'epoch': 1.21}\n",
      "{'loss': 0.3472, 'learning_rate': 3.2903055848261325e-05, 'epoch': 1.22}\n",
      "{'loss': 0.3405, 'learning_rate': 3.2639620653319283e-05, 'epoch': 1.24}\n",
      "{'loss': 0.3408, 'learning_rate': 3.237618545837724e-05, 'epoch': 1.25}\n",
      "{'loss': 0.3522, 'learning_rate': 3.21127502634352e-05, 'epoch': 1.27}\n",
      "{'loss': 0.3582, 'learning_rate': 3.184931506849315e-05, 'epoch': 1.28}\n",
      "{'loss': 0.3334, 'learning_rate': 3.1585879873551104e-05, 'epoch': 1.29}\n",
      "{'loss': 0.3333, 'learning_rate': 3.132244467860906e-05, 'epoch': 1.31}\n",
      "{'loss': 0.3096, 'learning_rate': 3.105900948366702e-05, 'epoch': 1.32}\n",
      "{'loss': 0.3556, 'learning_rate': 3.079557428872498e-05, 'epoch': 1.34}\n",
      "{'loss': 0.3403, 'learning_rate': 3.053213909378293e-05, 'epoch': 1.35}\n",
      "{'loss': 0.3608, 'learning_rate': 3.026870389884089e-05, 'epoch': 1.37}\n",
      "{'loss': 0.3313, 'learning_rate': 3.000526870389884e-05, 'epoch': 1.38}\n",
      "{'loss': 0.3311, 'learning_rate': 2.9741833508956796e-05, 'epoch': 1.39}\n",
      "{'loss': 0.3236, 'learning_rate': 2.9478398314014755e-05, 'epoch': 1.41}\n",
      "{'loss': 0.3398, 'learning_rate': 2.921496311907271e-05, 'epoch': 1.42}\n",
      "{'loss': 0.319, 'learning_rate': 2.8951527924130668e-05, 'epoch': 1.44}\n",
      "{'loss': 0.3212, 'learning_rate': 2.868809272918862e-05, 'epoch': 1.45}\n",
      "{'loss': 0.3256, 'learning_rate': 2.842465753424658e-05, 'epoch': 1.46}\n",
      "{'loss': 0.3349, 'learning_rate': 2.8161222339304533e-05, 'epoch': 1.48}\n",
      "{'loss': 0.303, 'learning_rate': 2.7897787144362485e-05, 'epoch': 1.49}\n",
      "{'loss': 0.3279, 'learning_rate': 2.7634351949420444e-05, 'epoch': 1.51}\n",
      "{'loss': 0.3234, 'learning_rate': 2.73709167544784e-05, 'epoch': 1.52}\n",
      "{'loss': 0.3341, 'learning_rate': 2.7107481559536357e-05, 'epoch': 1.54}\n",
      "{'loss': 0.3224, 'learning_rate': 2.6844046364594312e-05, 'epoch': 1.55}\n",
      "{'loss': 0.3352, 'learning_rate': 2.6580611169652264e-05, 'epoch': 1.56}\n",
      "{'loss': 0.3153, 'learning_rate': 2.6317175974710222e-05, 'epoch': 1.58}\n",
      "{'loss': 0.3294, 'learning_rate': 2.6053740779768177e-05, 'epoch': 1.59}\n",
      "{'loss': 0.3174, 'learning_rate': 2.5790305584826136e-05, 'epoch': 1.61}\n",
      "{'loss': 0.331, 'learning_rate': 2.5526870389884088e-05, 'epoch': 1.62}\n",
      "{'loss': 0.3428, 'learning_rate': 2.5263435194942046e-05, 'epoch': 1.64}\n",
      "{'loss': 0.2911, 'learning_rate': 2.5e-05, 'epoch': 1.65}\n",
      "{'loss': 0.3135, 'learning_rate': 2.4736564805057956e-05, 'epoch': 1.66}\n",
      "{'loss': 0.3049, 'learning_rate': 2.4473129610115915e-05, 'epoch': 1.68}\n",
      "{'loss': 0.3372, 'learning_rate': 2.420969441517387e-05, 'epoch': 1.69}\n",
      "{'loss': 0.314, 'learning_rate': 2.394625922023182e-05, 'epoch': 1.71}\n",
      "{'loss': 0.3268, 'learning_rate': 2.368282402528978e-05, 'epoch': 1.72}\n",
      "{'loss': 0.2879, 'learning_rate': 2.3419388830347735e-05, 'epoch': 1.73}\n",
      "{'loss': 0.3397, 'learning_rate': 2.315595363540569e-05, 'epoch': 1.75}\n",
      "{'loss': 0.3065, 'learning_rate': 2.289251844046365e-05, 'epoch': 1.76}\n",
      "{'loss': 0.336, 'learning_rate': 2.2629083245521604e-05, 'epoch': 1.78}\n",
      "{'loss': 0.3011, 'learning_rate': 2.236564805057956e-05, 'epoch': 1.79}\n",
      "{'loss': 0.3501, 'learning_rate': 2.2102212855637514e-05, 'epoch': 1.81}\n",
      "{'loss': 0.3099, 'learning_rate': 2.183877766069547e-05, 'epoch': 1.82}\n",
      "{'loss': 0.3133, 'learning_rate': 2.1575342465753427e-05, 'epoch': 1.83}\n",
      "{'loss': 0.296, 'learning_rate': 2.1311907270811383e-05, 'epoch': 1.85}\n",
      "{'loss': 0.3108, 'learning_rate': 2.1048472075869338e-05, 'epoch': 1.86}\n",
      "{'loss': 0.3063, 'learning_rate': 2.0785036880927293e-05, 'epoch': 1.88}\n",
      "{'loss': 0.2923, 'learning_rate': 2.0521601685985248e-05, 'epoch': 1.89}\n",
      "{'loss': 0.2993, 'learning_rate': 2.0258166491043203e-05, 'epoch': 1.91}\n",
      "{'loss': 0.3161, 'learning_rate': 1.999473129610116e-05, 'epoch': 1.92}\n",
      "{'loss': 0.3101, 'learning_rate': 1.9731296101159116e-05, 'epoch': 1.93}\n",
      "{'loss': 0.3155, 'learning_rate': 1.946786090621707e-05, 'epoch': 1.95}\n",
      "{'loss': 0.3164, 'learning_rate': 1.9204425711275027e-05, 'epoch': 1.96}\n",
      "{'loss': 0.3107, 'learning_rate': 1.894099051633298e-05, 'epoch': 1.98}\n",
      "{'loss': 0.3127, 'learning_rate': 1.8677555321390937e-05, 'epoch': 1.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eeded159c274312905d2f65b91564b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.24906396865844727, 'eval_f1': 0.8916800858829844, 'eval_runtime': 35.1191, 'eval_samples_per_second': 284.745, 'eval_steps_per_second': 8.913, 'epoch': 2.0}\n",
      "{'loss': 0.3086, 'learning_rate': 1.8414120126448895e-05, 'epoch': 2.0}\n",
      "{'loss': 0.3016, 'learning_rate': 1.815068493150685e-05, 'epoch': 2.02}\n",
      "{'loss': 0.3212, 'learning_rate': 1.7887249736564805e-05, 'epoch': 2.03}\n",
      "{'loss': 0.3007, 'learning_rate': 1.7623814541622764e-05, 'epoch': 2.05}\n",
      "{'loss': 0.2974, 'learning_rate': 1.7360379346680716e-05, 'epoch': 2.06}\n",
      "{'loss': 0.3427, 'learning_rate': 1.7096944151738674e-05, 'epoch': 2.08}\n",
      "{'loss': 0.3064, 'learning_rate': 1.683350895679663e-05, 'epoch': 2.09}\n",
      "{'loss': 0.2966, 'learning_rate': 1.6570073761854584e-05, 'epoch': 2.1}\n",
      "{'loss': 0.3136, 'learning_rate': 1.630663856691254e-05, 'epoch': 2.12}\n",
      "{'loss': 0.3077, 'learning_rate': 1.6043203371970498e-05, 'epoch': 2.13}\n",
      "{'loss': 0.3009, 'learning_rate': 1.577976817702845e-05, 'epoch': 2.15}\n",
      "{'loss': 0.2977, 'learning_rate': 1.5516332982086408e-05, 'epoch': 2.16}\n",
      "{'loss': 0.301, 'learning_rate': 1.5252897787144363e-05, 'epoch': 2.18}\n",
      "{'loss': 0.3156, 'learning_rate': 1.498946259220232e-05, 'epoch': 2.19}\n",
      "{'loss': 0.3212, 'learning_rate': 1.4726027397260275e-05, 'epoch': 2.2}\n",
      "{'loss': 0.3184, 'learning_rate': 1.4462592202318232e-05, 'epoch': 2.22}\n",
      "{'loss': 0.3197, 'learning_rate': 1.4199157007376185e-05, 'epoch': 2.23}\n",
      "{'loss': 0.3043, 'learning_rate': 1.3935721812434142e-05, 'epoch': 2.25}\n",
      "{'loss': 0.3099, 'learning_rate': 1.3672286617492097e-05, 'epoch': 2.26}\n",
      "{'loss': 0.3185, 'learning_rate': 1.3408851422550054e-05, 'epoch': 2.28}\n",
      "{'loss': 0.3062, 'learning_rate': 1.3145416227608009e-05, 'epoch': 2.29}\n",
      "{'loss': 0.273, 'learning_rate': 1.2881981032665966e-05, 'epoch': 2.3}\n",
      "{'loss': 0.2896, 'learning_rate': 1.2618545837723922e-05, 'epoch': 2.32}\n",
      "{'loss': 0.2933, 'learning_rate': 1.2355110642781877e-05, 'epoch': 2.33}\n",
      "{'loss': 0.3213, 'learning_rate': 1.209167544783983e-05, 'epoch': 2.35}\n",
      "{'loss': 0.3021, 'learning_rate': 1.1828240252897788e-05, 'epoch': 2.36}\n",
      "{'loss': 0.307, 'learning_rate': 1.1564805057955744e-05, 'epoch': 2.37}\n",
      "{'loss': 0.3063, 'learning_rate': 1.1301369863013698e-05, 'epoch': 2.39}\n",
      "{'loss': 0.2804, 'learning_rate': 1.1037934668071655e-05, 'epoch': 2.4}\n",
      "{'loss': 0.2981, 'learning_rate': 1.0774499473129611e-05, 'epoch': 2.42}\n",
      "{'loss': 0.2898, 'learning_rate': 1.0511064278187566e-05, 'epoch': 2.43}\n",
      "{'loss': 0.2937, 'learning_rate': 1.0247629083245521e-05, 'epoch': 2.45}\n",
      "{'loss': 0.3002, 'learning_rate': 9.984193888303478e-06, 'epoch': 2.46}\n",
      "{'loss': 0.2864, 'learning_rate': 9.720758693361433e-06, 'epoch': 2.47}\n",
      "{'loss': 0.3269, 'learning_rate': 9.457323498419388e-06, 'epoch': 2.49}\n",
      "{'loss': 0.2729, 'learning_rate': 9.193888303477345e-06, 'epoch': 2.5}\n",
      "{'loss': 0.3043, 'learning_rate': 8.930453108535302e-06, 'epoch': 2.52}\n",
      "{'loss': 0.308, 'learning_rate': 8.667017913593255e-06, 'epoch': 2.53}\n",
      "{'loss': 0.2831, 'learning_rate': 8.403582718651212e-06, 'epoch': 2.55}\n",
      "{'loss': 0.2872, 'learning_rate': 8.140147523709169e-06, 'epoch': 2.56}\n",
      "{'loss': 0.3168, 'learning_rate': 7.876712328767124e-06, 'epoch': 2.57}\n",
      "{'loss': 0.3305, 'learning_rate': 7.613277133825079e-06, 'epoch': 2.59}\n",
      "{'loss': 0.3066, 'learning_rate': 7.349841938883036e-06, 'epoch': 2.6}\n",
      "{'loss': 0.3033, 'learning_rate': 7.08640674394099e-06, 'epoch': 2.62}\n",
      "{'loss': 0.2792, 'learning_rate': 6.822971548998947e-06, 'epoch': 2.63}\n",
      "{'loss': 0.325, 'learning_rate': 6.559536354056903e-06, 'epoch': 2.64}\n",
      "{'loss': 0.2878, 'learning_rate': 6.296101159114858e-06, 'epoch': 2.66}\n",
      "{'loss': 0.2921, 'learning_rate': 6.032665964172814e-06, 'epoch': 2.67}\n",
      "{'loss': 0.3252, 'learning_rate': 5.76923076923077e-06, 'epoch': 2.69}\n",
      "{'loss': 0.3326, 'learning_rate': 5.505795574288726e-06, 'epoch': 2.7}\n",
      "{'loss': 0.3213, 'learning_rate': 5.242360379346681e-06, 'epoch': 2.72}\n",
      "{'loss': 0.3235, 'learning_rate': 4.978925184404637e-06, 'epoch': 2.73}\n",
      "{'loss': 0.3315, 'learning_rate': 4.715489989462593e-06, 'epoch': 2.74}\n",
      "{'loss': 0.2854, 'learning_rate': 4.452054794520548e-06, 'epoch': 2.76}\n",
      "{'loss': 0.3034, 'learning_rate': 4.188619599578504e-06, 'epoch': 2.77}\n",
      "{'loss': 0.3108, 'learning_rate': 3.92518440463646e-06, 'epoch': 2.79}\n",
      "{'loss': 0.2921, 'learning_rate': 3.661749209694415e-06, 'epoch': 2.8}\n",
      "{'loss': 0.2844, 'learning_rate': 3.398314014752371e-06, 'epoch': 2.82}\n",
      "{'loss': 0.329, 'learning_rate': 3.1348788198103265e-06, 'epoch': 2.83}\n",
      "{'loss': 0.3058, 'learning_rate': 2.8714436248682825e-06, 'epoch': 2.84}\n",
      "{'loss': 0.3136, 'learning_rate': 2.6080084299262384e-06, 'epoch': 2.86}\n",
      "{'loss': 0.3132, 'learning_rate': 2.3445732349841943e-06, 'epoch': 2.87}\n",
      "{'loss': 0.3142, 'learning_rate': 2.08113804004215e-06, 'epoch': 2.89}\n",
      "{'loss': 0.2935, 'learning_rate': 1.8177028451001056e-06, 'epoch': 2.9}\n",
      "{'loss': 0.2831, 'learning_rate': 1.554267650158061e-06, 'epoch': 2.92}\n",
      "{'loss': 0.2812, 'learning_rate': 1.290832455216017e-06, 'epoch': 2.93}\n",
      "{'loss': 0.318, 'learning_rate': 1.0273972602739725e-06, 'epoch': 2.94}\n",
      "{'loss': 0.3091, 'learning_rate': 7.639620653319284e-07, 'epoch': 2.96}\n",
      "{'loss': 0.294, 'learning_rate': 5.00526870389884e-07, 'epoch': 2.97}\n",
      "{'loss': 0.2881, 'learning_rate': 2.3709167544783985e-07, 'epoch': 2.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a927820a74946afbc88c600a90abe59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.23767633736133575, 'eval_f1': 0.8985352293381802, 'eval_runtime': 35.1681, 'eval_samples_per_second': 284.349, 'eval_steps_per_second': 8.9, 'epoch': 3.0}\n",
      "{'train_runtime': 5487.0869, 'train_samples_per_second': 49.206, 'train_steps_per_second': 0.384, 'train_loss': 0.3798611281663109, 'epoch': 3.0}\n",
      "***** train metrics *****\n",
      "  epoch                    =        3.0\n",
      "  train_loss               =     0.3799\n",
      "  train_runtime            = 1:31:27.08\n",
      "  train_samples_per_second =     49.206\n",
      "  train_steps_per_second   =      0.384\n"
     ]
    }
   ],
   "source": [
    "train_results = trainer.train()\n",
    "\n",
    "trainer.save_model()\n",
    "trainer.log_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "755850f224804fadbd3d65b6f9068040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** eval metrics *****\n",
      "  epoch                   =        3.0\n",
      "  eval_f1                 =     0.8985\n",
      "  eval_loss               =     0.2377\n",
      "  eval_runtime            = 0:00:34.88\n",
      "  eval_samples_per_second =    286.675\n",
      "  eval_steps_per_second   =      8.973\n"
     ]
    },
    {
     "ename": "LocalTokenNotFoundError",
     "evalue": "Token is required (`token=True`), but no token found. You need to provide a token or be logged in to Hugging Face with `huggingface-cli login` or `huggingface_hub.login`. See https://huggingface.co/settings/tokens.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLocalTokenNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32md:\\Code\\Project\\Java\\Kuliah\\Semester 5\\PCD\\proyek-akhir\\train.ipynb Cell 13\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/Project/Java/Kuliah/Semester%205/PCD/proyek-akhir/train.ipynb#X32sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m trainer\u001b[39m.\u001b[39mlog_metrics(\u001b[39m\"\u001b[39m\u001b[39meval\u001b[39m\u001b[39m\"\u001b[39m, metrics)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/Project/Java/Kuliah/Semester%205/PCD/proyek-akhir/train.ipynb#X32sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m trainer\u001b[39m.\u001b[39msave_metrics(\u001b[39m\"\u001b[39m\u001b[39meval\u001b[39m\u001b[39m\"\u001b[39m, metrics)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Code/Project/Java/Kuliah/Semester%205/PCD/proyek-akhir/train.ipynb#X32sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mpush_to_hub()\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\transformers\\trainer.py:3716\u001b[0m, in \u001b[0;36mTrainer.push_to_hub\u001b[1;34m(self, commit_message, blocking, **kwargs)\u001b[0m\n\u001b[0;32m   3713\u001b[0m \u001b[39m# If a user calls manually `push_to_hub` with `self.args.push_to_hub = False`, we try to create the repo but\u001b[39;00m\n\u001b[0;32m   3714\u001b[0m \u001b[39m# it might fail.\u001b[39;00m\n\u001b[0;32m   3715\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mrepo\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 3716\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minit_git_repo()\n\u001b[0;32m   3718\u001b[0m model_name \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mmodel_name\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m   3719\u001b[0m \u001b[39mif\u001b[39;00m model_name \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mshould_save:\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\transformers\\trainer.py:3566\u001b[0m, in \u001b[0;36mTrainer.init_git_repo\u001b[1;34m(self, at_init)\u001b[0m\n\u001b[0;32m   3564\u001b[0m     repo_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mhub_model_id\n\u001b[0;32m   3565\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m repo_name:\n\u001b[1;32m-> 3566\u001b[0m     repo_name \u001b[39m=\u001b[39m get_full_repo_name(repo_name, token\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49mhub_token)\n\u001b[0;32m   3568\u001b[0m \u001b[39m# Make sure the repo exists.\u001b[39;00m\n\u001b[0;32m   3569\u001b[0m create_repo(repo_name, token\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mhub_token, private\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mhub_private_repo, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\transformers\\utils\\hub.py:828\u001b[0m, in \u001b[0;36mget_full_repo_name\u001b[1;34m(model_id, organization, token)\u001b[0m\n\u001b[0;32m    826\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_full_repo_name\u001b[39m(model_id: \u001b[39mstr\u001b[39m, organization: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, token: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    827\u001b[0m     \u001b[39mif\u001b[39;00m organization \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 828\u001b[0m         username \u001b[39m=\u001b[39m whoami(token)[\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    829\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00musername\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mmodel_id\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\huggingface_hub\\hf_api.py:927\u001b[0m, in \u001b[0;36mHfApi.whoami\u001b[1;34m(self, token)\u001b[0m\n\u001b[0;32m    915\u001b[0m \u001b[39m@validate_hf_hub_args\u001b[39m\n\u001b[0;32m    916\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwhoami\u001b[39m(\u001b[39mself\u001b[39m, token: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict:\n\u001b[0;32m    917\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    918\u001b[0m \u001b[39m    Call HF API to know \"whoami\".\u001b[39;00m\n\u001b[0;32m    919\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[39m            not provided.\u001b[39;00m\n\u001b[0;32m    924\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m    925\u001b[0m     r \u001b[39m=\u001b[39m get_session()\u001b[39m.\u001b[39mget(\n\u001b[0;32m    926\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mendpoint\u001b[39m}\u001b[39;00m\u001b[39m/api/whoami-v2\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m--> 927\u001b[0m         headers\u001b[39m=\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_hf_headers(\n\u001b[0;32m    928\u001b[0m             \u001b[39m# If `token` is provided and not `None`, it will be used by default.\u001b[39;49;00m\n\u001b[0;32m    929\u001b[0m             \u001b[39m# Otherwise, the token must be retrieved from cache or env variable.\u001b[39;49;00m\n\u001b[0;32m    930\u001b[0m             token\u001b[39m=\u001b[39;49m(token \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtoken \u001b[39mor\u001b[39;49;00m \u001b[39mTrue\u001b[39;49;00m),\n\u001b[0;32m    931\u001b[0m         ),\n\u001b[0;32m    932\u001b[0m     )\n\u001b[0;32m    933\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    934\u001b[0m         hf_raise_for_status(r)\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\huggingface_hub\\hf_api.py:5008\u001b[0m, in \u001b[0;36mHfApi._build_hf_headers\u001b[1;34m(self, token, is_write_action, library_name, library_version, user_agent)\u001b[0m\n\u001b[0;32m   5005\u001b[0m \u001b[39mif\u001b[39;00m token \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   5006\u001b[0m     \u001b[39m# Cannot do `token = token or self.token` as token can be `False`.\u001b[39;00m\n\u001b[0;32m   5007\u001b[0m     token \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoken\n\u001b[1;32m-> 5008\u001b[0m \u001b[39mreturn\u001b[39;00m build_hf_headers(\n\u001b[0;32m   5009\u001b[0m     token\u001b[39m=\u001b[39;49mtoken,\n\u001b[0;32m   5010\u001b[0m     is_write_action\u001b[39m=\u001b[39;49mis_write_action,\n\u001b[0;32m   5011\u001b[0m     library_name\u001b[39m=\u001b[39;49mlibrary_name \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlibrary_name,\n\u001b[0;32m   5012\u001b[0m     library_version\u001b[39m=\u001b[39;49mlibrary_version \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlibrary_version,\n\u001b[0;32m   5013\u001b[0m     user_agent\u001b[39m=\u001b[39;49muser_agent \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49muser_agent,\n\u001b[0;32m   5014\u001b[0m )\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\huggingface_hub\\utils\\_headers.py:121\u001b[0m, in \u001b[0;36mbuild_hf_headers\u001b[1;34m(token, is_write_action, library_name, library_version, user_agent)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[39mBuild headers dictionary to send in a HF Hub call.\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39m        If `token=True` but token is not saved locally.\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[39m# Get auth token to send\u001b[39;00m\n\u001b[1;32m--> 121\u001b[0m token_to_send \u001b[39m=\u001b[39m get_token_to_send(token)\n\u001b[0;32m    122\u001b[0m _validate_token_to_send(token_to_send, is_write_action\u001b[39m=\u001b[39mis_write_action)\n\u001b[0;32m    124\u001b[0m \u001b[39m# Combine headers\u001b[39;00m\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\huggingface_hub\\utils\\_headers.py:153\u001b[0m, in \u001b[0;36mget_token_to_send\u001b[1;34m(token)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mif\u001b[39;00m token \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    152\u001b[0m     \u001b[39mif\u001b[39;00m cached_token \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m         \u001b[39mraise\u001b[39;00m LocalTokenNotFoundError(\n\u001b[0;32m    154\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mToken is required (`token=True`), but no token found. You\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    155\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m need to provide a token or be logged in to Hugging Face with\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    156\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m `huggingface-cli login` or `huggingface_hub.login`. See\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    157\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m https://huggingface.co/settings/tokens.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    158\u001b[0m         )\n\u001b[0;32m    159\u001b[0m     \u001b[39mreturn\u001b[39;00m cached_token\n\u001b[0;32m    161\u001b[0m \u001b[39m# Case implicit use of the token is forbidden by env variable\u001b[39;00m\n",
      "\u001b[1;31mLocalTokenNotFoundError\u001b[0m: Token is required (`token=True`), but no token found. You need to provide a token or be logged in to Hugging Face with `huggingface-cli login` or `huggingface_hub.login`. See https://huggingface.co/settings/tokens."
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate()\n",
    "# some nice to haves:\n",
    "trainer.log_metrics(\"eval\", metrics)\n",
    "trainer.save_metrics(\"eval\", metrics)\n",
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
